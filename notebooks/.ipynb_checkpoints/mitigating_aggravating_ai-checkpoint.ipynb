{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "from openai import AzureOpenAI, BadRequestError\n",
    "from dotenv import load_dotenv\n",
    "import re\n",
    "import logging\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "from mitigating_aggravating_ai_lists import aggravating_list, mitigating_list\n",
    "from bson import ObjectId\n",
    "import json\n",
    "from config import db_config\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(os.path.abspath(os.path.join(os.getcwd(), \"../config/.env\")))\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_KEY\"),\n",
    "    api_version=os.getenv(\"AZURE_OPENAI_VERSION\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hugging Face config\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"NbAiLab/nb-bert-base-ner\", model_max_length=512)\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    \"NbAiLab/nb-bert-base-ner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports judgements from the database or from a json file.\n",
    "def import_judgements(from_file: bool = False, file_path: str = \"../input/judgements.json\") -> list | pymongo.cursor.Cursor:\n",
    "    if from_file:\n",
    "        with open(file_path, \"r\") as f:\n",
    "            return json.load(f)\n",
    "    else:\n",
    "        return db_config.DB_LOCAL_DOMMEDAG[\"dommer\"].find()\n",
    "\n",
    "\n",
    "# Updates judgements in the database or json file.\n",
    "def update_judgement(judgements: list, judgement_id: str, circumstance_types: list, mitigating_or_aggravating: str, to_file: bool = False, file_path: str = \"../input/judgements.json\"):\n",
    "    if to_file:\n",
    "        for judgement in judgements:\n",
    "            if judgement[\"_id\"] == judgement_id:\n",
    "                judgement[mitigating_or_aggravating] = circumstance_types\n",
    "                break\n",
    "        with open(file_path, 'w') as file:\n",
    "            json.dump(judgements, file, indent=4)\n",
    "    else:\n",
    "        db_config.DB_LOCAL_DOMMEDAG[\"dommer_lr\"].update_one(\n",
    "            {'_id': ObjectId(judgement_id)},\n",
    "            {'$push': {mitigating_or_aggravating: circumstance_types}}\n",
    "        )\n",
    "\n",
    "\n",
    "# Splits the string into paragraphs using two newlines, including whitespace between them, as a separator\n",
    "def get_paragraphs(str):\n",
    "    paragraphs = re.split(r\"\\n\\s*\\n\", str)\n",
    "    return paragraphs\n",
    "\n",
    "\n",
    "\n",
    "def get_ai_response(system_prompt, user_example_1, assistant_example_1, user_example_2, assistant_example_2, user_example_3, assistant_example_3, paragraph):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"nrkddivundersokendesorost1106\",\n",
    "        response_format={ \"type\": \"json_object\" },\n",
    "        messages = [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": system_prompt\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": user_example_1\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": assistant_example_1\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": user_example_2\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": assistant_example_2\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": user_example_3\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": assistant_example_3\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": paragraph\n",
    "                },\n",
    "            ],\n",
    "        temperature=0,\n",
    "        max_tokens=2000,)\n",
    "    \n",
    "    response = completion.choices[0].message.content\n",
    "    time.sleep(2)\n",
    "    return json.loads(response)\n",
    "\n",
    "\n",
    "# Replaces names in a string with only the text \"Navn\".\n",
    "def replace_names_with_placeholder(input_str):\n",
    "    nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
    "    ner_results = nlp(input_str)\n",
    "    reversed_ner_results = list(reversed(ner_results))\n",
    "\n",
    "    for entity in reversed_ner_results:\n",
    "        if entity[\"entity\"] == \"B-PER\":\n",
    "            if \"##\" in entity[\"word\"]:\n",
    "                input_str = input_str[:entity[\"start\"]] + \\\n",
    "                    input_str[entity[\"end\"]:]\n",
    "            else:\n",
    "                input_str = input_str[:entity[\"start\"]] + \"Navn\" + input_str[entity[\"end\"]:]\n",
    "        elif entity[\"entity\"] == \"I-PER\":\n",
    "            if \"##\" in entity[\"word\"]:\n",
    "                input_str = input_str[:entity[\"start\"]] + \\\n",
    "                    input_str[entity[\"end\"]:]\n",
    "            else:\n",
    "                input_str = input_str[:entity[\"start\"]] + input_str[entity[\"end\"]:]\n",
    "\n",
    "    return input_str.replace(\"  \", \" \")\n",
    "\n",
    "\n",
    "\n",
    "def replace_dates(text):\n",
    "    # Pattern for \"dd.mm.yyyy\" format\n",
    "    pattern1 = r\"\\d{1,2}\\.\\s?\\d{1,2}\\.\\s?\\d{4}\"\n",
    "\n",
    "    # Pattern for \"dd. month yyyy\" format\n",
    "    months = \"januar|februar|mars|april|mai|juni|juli|august|september|oktober|november|desember\"\n",
    "    pattern2 = r\"\\d{1,2}\\.\\s?(\" + months + r\")(\\s?\\d{4})?\"\n",
    "\n",
    "    # Combined pattern with an 'or' condition\n",
    "    combined_pattern = f\"({pattern1})|({pattern2})\"\n",
    "\n",
    "    return re.sub(combined_pattern, \"DATO\", text)\n",
    "\n",
    "\n",
    "def count_word(text, word):\n",
    "  text = text.lower()\n",
    "  word = word.lower()\n",
    "  words = text.split()\n",
    "  count = words.count(word)\n",
    "\n",
    "  return count\n",
    "\n",
    "# Checks if mitigating or aggravating circumstances are written in past tense.\n",
    "# Returns True if any of the past tense formulations in the list are found AND the word mitigating or aggravating is only found once in the paragraph\n",
    "def circumstance_is_in_past_tense(paragraph, mitigating=True) -> bool:\n",
    "    if mitigating:\n",
    "        if count_word(paragraph, \"formildende\") == 1 or count_word(paragraph, \"formildande\") == 1:\n",
    "            mitigating_past_tense_list = [\"var formildende\", \"var formildande\", \"forelå formildende\", \"forelå formildande\", \"formildende omstendigheter var\", \"formildande omstende var\"]\n",
    "            for string in mitigating_past_tense_list:\n",
    "                if string in paragraph:\n",
    "                    logging.info(f\"Found paragraph in past tense: {paragraph}\")\n",
    "                    return True\n",
    "        return False\n",
    "    else:\n",
    "        paragraph = paragraph.replace(\"straffeskjerpende\", \"skjerpende\")\n",
    "        paragraph = paragraph.replace(\"straffeskjerpande\", \"skjerpande\")\n",
    "        if count_word(paragraph, \"skjerpende\") == 1 or count_word(paragraph, \"skjerpande\") == 1:\n",
    "            aggravating_past_tense_list = [\"var skjerpende\", \"var skjerpande\", \"forelå skjerpende\", \"forelå skjerpande\", \"skjerpende omstendigheter var\", \"skjerpande omstende var\"]\n",
    "            for string in aggravating_past_tense_list:\n",
    "                if string in paragraph:\n",
    "                    logging.info(f\"Found paragraph in past tense: {paragraph}\")\n",
    "                    return True\n",
    "        return False\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI prompts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt_aggravating = \"\"\"\n",
    "Du er en assistent som leser korte tekstutdrag fra dommer. Du skal avgjøre om teksten inneholder informasjon om hvilke eventuelle skjerpende eller straffeskjerpende omstendigheter det er i saken. Du skal identifisere den mest relevante skjerpende eller straffeskjerpende omstendigheten fra listen nedenfor og angi den i JSON-format på engelsk.\n",
    "Du skal kun nevne omstendigheter det står at er skjerpende eller straffeskjerpende for denne dommen, ikke omstendigheter for tidligere dommer. Dersom det ikke står at omstendigheten er skjerpende eller straffeskjerpende, eller hvis teksten om omstendigheten er skrevet i fortid, skal du svare {\"aggravating\": \"false\"}.\n",
    "Du skal svare i json-format på engelsk på denne måten: {\"aggravating\": \"death threats\"}. Nevn kun én skjerpende eller straffeskjerpende omstendighet, den du tror er viktigst.\n",
    "Hvis du ikke finner en relevant omstendighet i listen, svarer du {\"aggravating\": \"other circumstances\"}. Hvis det mangler informasjon om skjerpende eller straffeskjerpende omstendigheter, eller hvis du ikke klarer å tolke det, skal du svare {\"aggravating\": \"false\"}.\n",
    "Hvis formuleringen om omstendigheten er skrevet i fortid, for eksempel \"det var skjerpende\" eller \"det forelå skjerpende\", skal du svare {\"aggravating\": \"false\"}.\n",
    "Her er listen:\n",
    "\"\"\" + aggravating_list\n",
    "\n",
    "system_prompt_mitigating = \"\"\"\n",
    "Du er en assistent som leser korte tekstutdrag fra dommer. Du skal avgjøre om teksten inneholder informasjon om hvilke eventuelle formildende omstendigheter det er i saken. Du skal identifisere den mest relevante formildende omstendigheten fra listen nedenfor og angi den i JSON-format på engelsk.\n",
    "Du skal kun nevne omstendigheter det står at er formildende for denne saken, ikke omstendigheter som er formildende for tidligere rettssaker. Dersom det ikke står at omstendigheten er formildende, eller hvis teksten om omstendigheten er skrevet i fortid, skal du svare {\"mitigating\": \"false\"}.\n",
    "Du skal svare i json-format på engelsk på denne måten: {\"mitigating\": \"self defense\"}. Nevn kun én formildende omstendighet, den du tror er viktigst.\n",
    "Hvis du ikke finner en relevant omstendighet i listen, svarer du {\"mitigating\": \"other circumstances\"}. Hvis det mangler informasjon om formildende omstendigheter eller hvis du ikke klarer å tolke det skal du svare {\"mitigating\": \"false\"}.\n",
    "Hvis formuleringen om omstendigheten er skrevet i fortid, for eksempel \"det var formildende\" eller \"det forelå formildende\", skal du svare {\"mitigating\": \"false\"}.\n",
    "Her er listen:\n",
    "\"\"\" + mitigating_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examples for aggravating paragraphs and assistant response\n",
    "\n",
    "user_example_1_aggravating = \"I skjerpende retning legger retten vekt på at Navn kjørte i ruspåvirket tilstand.\"\n",
    "\n",
    "assistant_example_1_aggravating = \"\"\"{\"aggravating\": \"driving under influence\"}\"\"\"\n",
    "\n",
    "user_example_2_aggravating = \"\"\"\n",
    "Navn ble ved Kristiansand tingretts dom av DATO dømt til forvaring i 16 år \n",
    "med minstetid på 10 år for overlagt drap under særdeles skjerpende omstendigheter. Etter anke ble straffen \n",
    "fastsatt til forvaring.\n",
    "\"\"\"\n",
    "\n",
    "assistant_example_2_aggravating = \"\"\"{\"aggravating\": \"false\"}\"\"\"\n",
    "\n",
    "user_example_3_aggravating = \"\"\"\n",
    "Overtredelsen i post I ville medført en kortere betinget straff, \n",
    "og tillegges vekt i straffeskjerpende retning.\n",
    "\"\"\"\n",
    "\n",
    "assistant_example_3_aggravating = \"\"\"{\"aggravating\": \"other circumstances\"}\"\"\"\n",
    "\n",
    "# Examples for mitigating paragraphs and assistant response\n",
    "\n",
    "user_example_1_mitigating = \"I formildende retning legger retten vekt på at Navn har gitt en uforbeholden tilståelse.\"\n",
    "\n",
    "assistant_example_1_mitigating = \"\"\"{\"mitigating\": \"confession\"}\"\"\"\n",
    "\n",
    "user_example_2_mitigating = \"\"\"\n",
    "Saken gjaldt straffutmåling for uaktsomt heleri. Det var formildende at de domfelte \n",
    "hadde samarbeidet med politiet og møtt som vitner i saken mot hovedmannen, \n",
    "og at straffeforfølgningen hadde tatt lang tid.\n",
    "\"\"\"\n",
    "\n",
    "assistant_example_2_mitigating = \"\"\"{\"mitigating\": \"false\"}\"\"\"\n",
    "\n",
    "user_example_3_mitigating = \"\"\"\n",
    "Det forelå formildende omstendigheter, ettersom hun hadde daglig omsorg for det yngste barnet. \n",
    "Dommen er etter gammel straffelov, og før strafferammen ble \n",
    "økt, men samtidig er tidsperioden lengre enn i denne sak.  \n",
    "\"\"\"\n",
    "\n",
    "assistant_example_3_mitigating = \"\"\"{\"mitigating\": \"false\"}\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main processing loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If importing from json file, set the first argument to True and optionally the second argument to file path (\"If file path is different than \"../input/judgements.json\"\")\n",
    "judgements = import_judgements()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "\n",
    "# Loop through judgements\n",
    "for judgement in judgements:\n",
    "    judgement_id = judgement[\"_id\"]\n",
    "    num += 1\n",
    "    logging.info(f\"Judgement {num}\")\n",
    "    logging.info(judgement_id)\n",
    "\n",
    "    judgement_text = judgement[\"dom_tekst\"]\n",
    "    # Split text into list of paragraphs\n",
    "    paragraphs = get_paragraphs(judgement_text)\n",
    "\n",
    "    aggravating_circumstances = []\n",
    "    mitigating_circumstances = []\n",
    "\n",
    "    for paragraph in paragraphs:\n",
    "        try:\n",
    "            if \"skjerpende\" in paragraph.lower() or \"skjerpande\" in paragraph.lower():\n",
    "\n",
    "                if circumstance_is_in_past_tense(paragraph, False):\n",
    "                    continue\n",
    "\n",
    "                paragraph_without_names = replace_names_with_placeholder(\n",
    "                    paragraph)\n",
    "                paragraph_without_names_and_dates = replace_dates(\n",
    "                    paragraph_without_names)\n",
    "                ai_response = get_ai_response(system_prompt_aggravating, user_example_1_aggravating, assistant_example_1_aggravating, user_example_2_aggravating,\n",
    "                                              assistant_example_2_aggravating, user_example_3_aggravating, assistant_example_3_aggravating, paragraph_without_names_and_dates)\n",
    "                if ai_response == {\"aggravating\": \"false\"}:\n",
    "                    logging.info(\"No match for aggravating circumstance:\")\n",
    "                    logging.info(paragraph_without_names_and_dates)\n",
    "                else:\n",
    "                    logging.info(ai_response)\n",
    "                    logging.info(paragraph_without_names_and_dates)\n",
    "                    aggravating_circumstances.append(\n",
    "                        ai_response[\"aggravating\"])\n",
    "            if \"formildende\" in paragraph.lower() or \"formildande\" in paragraph.lower():\n",
    "                if circumstance_is_in_past_tense(paragraph):\n",
    "                    continue\n",
    "\n",
    "                paragraph_without_names = replace_names_with_placeholder(\n",
    "                    paragraph)\n",
    "                paragraph_without_names_and_dates = replace_dates(\n",
    "                    paragraph_without_names)\n",
    "                ai_response = get_ai_response(system_prompt_mitigating, user_example_1_mitigating, assistant_example_1_mitigating, user_example_2_mitigating,\n",
    "                                              assistant_example_2_mitigating, user_example_3_aggravating, assistant_example_3_aggravating, paragraph_without_names_and_dates)\n",
    "                if ai_response == {\"mitigating\": \"false\"}:\n",
    "                    logging.info(\"No match for mitigating circumstance:\")\n",
    "                    logging.info(paragraph_without_names_and_dates)\n",
    "                else:\n",
    "                    logging.info(ai_response)\n",
    "                    logging.info(paragraph_without_names_and_dates)\n",
    "                    mitigating_circumstances.append(ai_response[\"mitigating\"])\n",
    "                    print(\"**************************\")\n",
    "        except BadRequestError as e:\n",
    "            logging.info(f\"BadRequestError: {e}\")\n",
    "\n",
    "    aggravating_circumstances = list(set(aggravating_circumstances))\n",
    "    mitigating_circumstances = list(set(mitigating_circumstances))\n",
    "\n",
    "    logging.info(aggravating_circumstances)\n",
    "    if aggravating_circumstances:\n",
    "        update_judgement(judgements, judgement_id,\n",
    "                         aggravating_circumstances, \"aggravating\")\n",
    "\n",
    "    logging.info(mitigating_circumstances)\n",
    "    if mitigating_circumstances:\n",
    "        update_judgement(judgements, judgement_id,\n",
    "                         mitigating_circumstances, \"mitigating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
